{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation code\n",
    "\n",
    "A couple of raw code examples of forward propagation calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_data = np.array([2,3])\n",
    "weights= {'node_0': np.array([1, 1]),\n",
    "          'node_1': np.array([-1, 1]),\n",
    "          'output': np.array([2, -1])}\n",
    "\n",
    "node_0_value = (input_data * weights['node_0']).sum()\n",
    "node_1_value = (input_data * weights['node_1']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(node_0_value)\n",
    "print(node_1_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 1]\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_values = np.array([node_0_value, node_1_value])\n",
    "print(hidden_layer_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "output = (hidden_layer_values * weights['output']).sum()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For maximum predictive power we have to implement an activation function in the hidden layers in order to capture 'non-linearities'\n",
    "\n",
    "For this we distinguish the input from the output in each neuron in the hidden layer, where the output implements the Activation Function 'ReLU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23822425257\n"
     ]
    }
   ],
   "source": [
    "# Given the weights lets redraw the model\n",
    "node_0_input = (input_data * weights['node_0']).sum()\n",
    "node_0_output = np.tanh(node_0_input)\n",
    "\n",
    "node_1_input = (input_data * weights['node_1']).sum()\n",
    "node_1_output = np.tanh(node_1_input)\n",
    "\n",
    "hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "\n",
    "output = (hidden_layer_outputs * weights['output']).sum()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'ReLU' Activation Function outputs the maximum of (input, 0) as a linear number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(input):\n",
    "    return max(input, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewriting the example above, replacing the tanh with the ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "node_0_input = (input_data * weights['node_0']).sum()\n",
    "node_0_output = relu(node_0_input)\n",
    "\n",
    "node_1_input = (input_data * weights['node_1']).sum()\n",
    "node_1_output = relu(node_1_input)\n",
    "\n",
    "hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "\n",
    "output = (hidden_layer_outputs * weights['output']).sum()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to generalize the model to work with multiple observations, we will define a function which will generate predictions for an array of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_with_network(input_data_row, weights):\n",
    "    \n",
    "    node_0_0_input = (input_data_row * weights['node_0_0']).sum()\n",
    "    node_0_0_output = relu(node_0_0_input)\n",
    "    \n",
    "    node_0_1_input = (input_data_row * weights['node_0_1']).sum()\n",
    "    node_0_1_output = relu(node_0_1_input)\n",
    "    \n",
    "    hidden_0_output = np.array([node_0_0_output, node_0_1_output])\n",
    "    \n",
    "    node_1_0_input = (hidden_0_output * weights['node_1_0']).sum()\n",
    "    node_1_0_output = relu(node_1_0_input)\n",
    "    \n",
    "    node_1_1_input = (hidden_0_output * weights['node_1_1']).sum()\n",
    "    node_1_1_output = relu(node_1_1_input)\n",
    "    \n",
    "    hidden_1_output = np.array([node_1_0_output, node_1_1_output])\n",
    "    \n",
    "    input_to_final_layer = (hidden_1_output * weights['output']).sum()\n",
    "    model_output = relu(input_to_final_layer)\n",
    "    \n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for input_data_row in input_data:\n",
    "    results.append(predict_with_network(input_data_row, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Optimizer Function\n",
    "\n",
    "\n",
    "First we need to implement a loss function to measure the process at which we learn to approximate the real distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create model_output_0 \n",
    "model_output_0 = []\n",
    "# Create model_output_0\n",
    "model_output_1 = []\n",
    "\n",
    "# Loop over input_data\n",
    "for row in input_data:\n",
    "    # Append prediction to model_output_0\n",
    "    model_output_0.append(predict_with_network(row, weights_0))\n",
    "    \n",
    "    # Append prediction to model_output_1\n",
    "    model_output_1.append(predict_with_network(row, weights_1))\n",
    "\n",
    "# Calculate the mean squared error for model_output_0: mse_0\n",
    "mse_0 = mean_squared_error(model_output_0, target_actuals)\n",
    "\n",
    "# Calculate the mean squared error for model_output_1: mse_1\n",
    "mse_1 = mean_squared_error(model_output_1, target_actuals)\n",
    "\n",
    "# Print mse_0 and mse_1\n",
    "print(\"Mean squared error with weights_0: %f\" %mse_0)\n",
    "print(\"Mean squared error with weights_1: %f\" %mse_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent update Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "weights = np.array([1,2])\n",
    "input_data = np.array([3,4])\n",
    "\n",
    "target = 6\n",
    "learning_rate = 0.01\n",
    "\n",
    "preds = (weights * input_data).sum()\n",
    "error = preds - target\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the slope of the current Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 40])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient = 2 * input_data * error\n",
    "gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_updated = weights - learning_rate * gradient\n",
    "preds_updated = (weights_updated * input_data).sum()\n",
    "error_updated = preds_updated - target\n",
    "error_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_slope(input_data, target, weights):\n",
    "    preds = (input_data * weights).sum()\n",
    "    error = preds - target\n",
    "    return 2 * input_data * error\n",
    "\n",
    "\n",
    "def get_mse(input_data, target, weights):\n",
    "    preds = (input_data * weights).sum()\n",
    "    return mse(target, preds)\n",
    "\n",
    "\n",
    "n_updates = 20\n",
    "mse_hist = []\n",
    "\n",
    "for i in range(n_updates):\n",
    "    slope = get_slope(input_data, target, weights)\n",
    "    \n",
    "    weights = weights - 0.01 * slope\n",
    "    \n",
    "    mse = get_mse(input_data, target, weights)\n",
    "    \n",
    "    mse_hist.append(mse)\n",
    "    \n",
    "\n",
    "# Plot the mse History\n",
    "plt.plot(mse_hist)\n",
    "plt.xlabel('Iterations')\n",
    "ply.ylabel('Mean Squared Error')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Keras Model\n",
    "\n",
    "- 1) You specifiy the architecture\n",
    "- 2) You compile the model\n",
    "- 3) You fit the model (Backprop, Model weight approximation)\n",
    "- 4) Predict with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Model Specification\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "predictors = np.loadtxt('predictors_data.csv', delimiter=',')\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify the optimizer\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Scaling the data\n",
    "\n",
    "# Fitting the model with prescaled Features\n",
    "model.fit(predictors, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
